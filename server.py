"""åŸºé‡‘ä¼°å€¼åŠ©æ‰‹ - A2A + FastAPI æœåŠ¡"""

import os
import sys
import json
import asyncio
import urllib.request
from datetime import datetime
from typing import Optional, List, Dict
import numpy as np
from contextlib import asynccontextmanager

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from dotenv import load_dotenv
load_dotenv()

# HuggingFace endpoint mirror (useful for China networks)
os.environ.setdefault("HF_ENDPOINT", "https://hf-mirror.com")

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Header, HTTPException, Query, Body, Request
from fastapi.middleware.cors import CORSMiddleware
from utils.middleware import APIResponse
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel

from hello_agents import HelloAgentsLLM
from hello_agents.protocols.a2a import A2AServer

# å¯¼å…¥ Agents
from agents import (
    create_coordinator_agent,
    create_quant_agent,
    create_analyst_agent,
    create_advisor_agent,
    create_strategist_agent,
    create_intelligence_agent,
    create_intelligence_agent,
    create_shadow_analyst_agent
)
from agents.daily_report_agent import DailyReportAgent
from tools.market_data import get_market_service
from tools.fund_tools import FundDataTool
from tools.portfolio_tools import PortfolioTool

# å¯¼å…¥è®¤è¯å’Œæ•°æ®åº“
from utils.auth import create_token, decode_token, get_user_repo, get_current_user, get_current_user_optional
from utils.database import get_database, get_chat_repo
from utils.config import get_config, print_config_status, validate_config

# å¯¼å…¥è®°å¿†å’Œ RAG æœåŠ¡
from utils.memory_service import get_memory_service, FundMemoryService

import logging
logger = logging.getLogger("fund_assistant")
logging.basicConfig(level=logging.INFO)
from utils.rag_service import get_rag_service, FundRAGService
from utils.context_service import get_context_service, FundContextService

# å¯¼å…¥å›¾è¡¨ API
from api.chart_api import router as chart_router
from api.discovery_api import router as discovery_router
from api.portfolio_api import router as portfolio_router
from api.investment_api import router as investment_router
from api.category_api import router as category_router
from api.shadow_api import router as shadow_router
from api.analytics_api import router as analytics_router
from api.account_api import router as account_router


# ============ Pydantic Models ============

class ChatMessage(BaseModel):
    message: str
    agent: Optional[str] = "strategist"
    session_id: Optional[str] = None

class HoldingAdd(BaseModel):
    fund_code: str
    fund_name: Optional[str] = ""
    shares: float
    cost_nav: float


class UserLogin(BaseModel):
    username: str
    password: str


# ============ è®¤è¯ä¾èµ– ============

from fastapi import Depends




# ============ è®¤è¯ä¾èµ– ============

from fastapi import Depends
from utils.auth import get_current_user, get_current_user_optional

# Backward-compatible alias for admin routes
require_auth = get_current_user

# Replaced local get_current_user/require_auth with utils.auth dependencies


# ============ å…¨å±€å˜é‡ ============

llm = None
agents = {}
fund_tool = None
portfolio_tool = None
memory_service: FundMemoryService = None
rag_service: FundRAGService = None


# ============ ç”Ÿå‘½å‘¨æœŸ ============

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global llm, agents, fund_tool, portfolio_tool, memory_service, rag_service
    
    # åˆå§‹åŒ–æ—¥å¿—
    from utils.logging_config import setup_logging, get_logger
    setup_logging(level="DEBUG" if os.getenv("DEBUG", "").lower() == "true" else "INFO")
    logger = get_logger()
    
    logger.info("=" * 60)
    logger.info("ğŸš€ åŸºé‡‘ä¼°å€¼åŠ©æ‰‹ - HelloAgents æ¡†æ¶ç‰ˆ")
    logger.info("=" * 60)
    
    # é…ç½®éªŒè¯
    config = get_config()
    print_config_status()
    
    # æ£€æŸ¥ LLM é…ç½®
    validation = validate_config()
    if not validation["config_summary"]["llm_configured"]:
        logger.warning("LLM æœªé…ç½®ï¼ŒAgent å°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”")
    
    # åˆå§‹åŒ– LLM
    try:
        llm = HelloAgentsLLM()
        logger.info("âœ… LLM åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.warning(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        llm = None
    
    # åˆå§‹åŒ–å·¥å…·
    # åˆå§‹åŒ–å·¥å…·
    fund_tool = FundDataTool()
    portfolio_tool = PortfolioTool()  # Uses default ./data/fund_assistant.db
    logger.info("âœ… å·¥å…·åˆå§‹åŒ–å®Œæˆ")
    
    # åˆå§‹åŒ–è®°å¿†æœåŠ¡
    try:
        memory_service = get_memory_service("default_user")
        logger.info("âœ… è®°å¿†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.warning(f"è®°å¿†æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        memory_service = None
    
    # åˆå§‹åŒ– RAG æœåŠ¡
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            # ç´¢å¼•çŸ¥è¯†åº“
            logger.info("ğŸ“š æ­£åœ¨ç´¢å¼•çŸ¥è¯†åº“...")
            rag_service.index_knowledge_base()
            logger.info("âœ… RAG æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        else:
            logger.warning("RAG æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
    except Exception as e:
        logger.warning(f"RAG æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        rag_service = None
    
    # åˆå§‹åŒ– Agents (ä»…å½“ LLM å¯ç”¨æ—¶)
    if llm:
        agents = {
            "coordinator": create_coordinator_agent(llm),
            "quant": create_quant_agent(llm),
            "analyst": create_analyst_agent(llm),
            "advisor": create_advisor_agent(llm),
            "strategist": create_strategist_agent(llm),
            "intelligence": create_intelligence_agent(llm),
            "shadow_analyst": create_shadow_analyst_agent(llm),
            "daily_report": DailyReportAgent(llm, get_market_service())
        }
        logger.info(f"âœ… 8 ä¸ª Agent åˆå§‹åŒ–å®Œæˆ")
        for name, agent in agents.items():
            logger.debug(f"   ğŸ“¡ {agent.name} ({name})")
    else:
        logger.warning("Agent åŠŸèƒ½ä¸å¯ç”¨ (éœ€è¦é…ç½® LLM)")
        
    # åˆå§‹åŒ–æ¿å—æ•°æ®
    try:
        from services.category_service import get_category_service
        logger.info("ğŸ“Š æ­£åœ¨åˆ·æ–°æ¿å—æŒ‡æ•°...")
        await get_category_service().refresh_all_indices()
    except Exception as e:
        logger.warning(f"æ¿å—æŒ‡æ•°åˆ·æ–°å¤±è´¥: {e}")
    
    # å¯åŠ¨å…¨é‡è¡Œæƒ…åå°åˆ·æ–°ä»»åŠ¡
    asyncio.create_task(refresh_global_market_task())
    
    logger.info("=" * 60)
    logger.info(f"ğŸŒ è®¿é—®: http://localhost:{config.server.port}")
    logger.info("=" * 60)
    
    yield
    
    logger.info("ğŸ‘‹ æœåŠ¡å…³é—­")


# ============ FastAPI åº”ç”¨ ============

app = FastAPI(title="åŸºé‡‘ä¼°å€¼åŠ©æ‰‹", lifespan=lifespan)

# æ³¨å†Œè‡ªå®šä¹‰ä¸­é—´ä»¶
from utils.middleware import add_middlewares
add_middlewares(app)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶
frontend_path = os.path.join(os.path.dirname(__file__), "frontend")
if os.path.exists(frontend_path):
    app.mount("/static", StaticFiles(directory=frontend_path), name="static")
    
    # Mount assets for Vite build
    assets_path = os.path.join(frontend_path, "assets")
    if os.path.exists(assets_path):
        app.mount("/assets", StaticFiles(directory=assets_path), name="assets")

# V3 å‰ç«¯é™æ€æ–‡ä»¶
frontend_v3_path = os.path.join(os.path.dirname(__file__), "frontend-v3")
if os.path.exists(frontend_v3_path):
    app.mount("/v3-static", StaticFiles(directory=frontend_v3_path), name="static-v3")

# æ³¨å†Œè®¤è¯ API è·¯ç”±
from api.auth_api import router as auth_router
app.include_router(auth_router)

# æ³¨å†Œå›¾è¡¨ API è·¯ç”±
app.include_router(chart_router)
app.include_router(discovery_router)
app.include_router(portfolio_router)
app.include_router(investment_router)
app.include_router(category_router)
app.include_router(shadow_router)
app.include_router(analytics_router)
app.include_router(account_router)  # P3: Multi-account system


# ============ è·¯ç”± ============

@app.get("/")
async def root():
    """é¦–é¡µ"""
    index_path = os.path.join(frontend_path, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"message": "åŸºé‡‘ä¼°å€¼åŠ©æ‰‹ API", "status": "running"}


@app.get("/api/market/rankings")
async def get_market_rankings(
    sort: str = Query("1r", description="æ’åºæ–¹å¼: 1r/1w/1m/3m/6m/1y/n"),
    limit: int = Query(20, description="è¿”å›æ•°é‡"),
    request: Request = None
):
    """è·å–åŸºé‡‘æ’è¡Œ (å®æ—¶)"""
    try:
        service = get_market_service()
        # Use simple get_fund_rankings if available, or fallback
        if hasattr(service, "get_fund_rankings"):
            data = service.get_fund_rankings(sort_by=sort, limit=limit)
             # Convert dataclass list to dict list
            return APIResponse.success([d.to_dict() for d in data])
        else:
             return APIResponse.error("Data source does not support rankings")
    except Exception as e:
        logger.error(f"Error fetching rankings: {e}")
        return APIResponse.error(str(e))


@app.get("/shadow")
async def shadow_page():
    """å½±å­è¿½è¸ªé¡µé¢"""
    shadow_path = os.path.join(frontend_path, "shadow.html")
    if os.path.exists(shadow_path):
        return FileResponse(shadow_path)
    return {"error": "Shadow tracker page not found"}


@app.get("/v2")
async def v2_page():
    """æ–°ç‰ˆ UI (åå°”è¡—çº§ä¸“ä¸šç•Œé¢)"""
    v2_path = os.path.join(frontend_path, "index-v2.html")
    if os.path.exists(v2_path):
        return FileResponse(v2_path)
    return {"error": "V2 page not found"}


@app.get("/v3")
async def v3_page():
    """V3 æ–°ç‰ˆ UI (æ¡Œé¢ç«¯ä¸“ä¸šæ¶æ„)"""
    v3_path = os.path.join(os.path.dirname(frontend_path), "frontend-v3", "index.html")
    if os.path.exists(v3_path):
        return FileResponse(v3_path)
    return {"error": "V3 page not found"}


@app.get("/api/info")
async def get_info():
    """è·å–æœåŠ¡ä¿¡æ¯"""
    return {
        "name": "åŸºé‡‘ä¼°å€¼åŠ©æ‰‹",
        "version": "2.0.0",
        "framework": "HelloAgents",
        "agents": list(agents.keys()),
        "paradigms": {
            "coordinator": "ReActAgent",
            "quant": "SimpleAgent",
            "analyst": "ReflectionAgent",
            "advisor": "PlanAndSolveAgent",
            "strategist": "ReActAgent",
            "intelligence": "ReActAgent",
            "shadow_analyst": "ReActAgent"
        }
    }


@app.get("/api/health")
async def health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    from utils.database import get_database
    
    health = {
        "status": "healthy",
        "checks": {}
    }
    
    # æ£€æŸ¥æ•°æ®åº“
    try:
        db = get_database()
        with db.get_connection() as conn:
            conn.execute("SELECT 1")
        health["checks"]["database"] = {"status": "ok"}
    except Exception as e:
        health["checks"]["database"] = {"status": "error", "message": str(e)}
        health["status"] = "degraded"
    
    # æ£€æŸ¥ LLM
    if llm:
        health["checks"]["llm"] = {"status": "ok", "configured": True}
    else:
        health["checks"]["llm"] = {"status": "warning", "configured": False}
    
    # æ£€æŸ¥ Agents
    health["checks"]["agents"] = {
        "status": "ok" if agents else "warning",
        "count": len(agents)
    }
    
    return health


@app.get("/api/health/datasource")
async def datasource_health():
    """æ•°æ®æºå¥åº·æ£€æŸ¥"""
    from tools.market_data import get_market_service
    
    service = get_market_service()
    health = service.get_health()
    
    # ä¸»åŠ¨æ£€æŸ¥å„æ•°æ®æº
    checks = {}
    for source_name in ["eastmoney_mobile", "eastmoney", "akshare"]:
        checks[source_name] = service.check_source_health(source_name)
    
    health["active_checks"] = checks
    
    # åˆ¤æ–­æ•´ä½“çŠ¶æ€
    if any(c["status"] == "ok" for c in checks.values()):
        health["overall_status"] = "ok"
    elif any(c["status"] == "degraded" for c in checks.values()):
        health["overall_status"] = "degraded"
    else:
        health["overall_status"] = "error"
    
    # P0: ä¸ºå‰ç«¯ 'auto' æ¨¡å¼æä¾›çŠ¶æ€æ”¯æŒ
    if health["preferred_source"] == "auto":
        health["active_checks"]["auto"] = {
            "status": health["overall_status"],
            "source": "auto"
        }
    
    return health


@app.get("/api/metrics")
async def get_metrics(format: str = "json"):
    """è·å–åº”ç”¨æŒ‡æ ‡"""
    from utils.metrics import get_metrics_collector
    
    collector = get_metrics_collector()
    
    if format == "prometheus":
        from fastapi.responses import PlainTextResponse
        return PlainTextResponse(
            content=collector.get_prometheus_format(),
            media_type="text/plain"
        )
    
    return collector.get_metrics()


@app.post("/api/chat")
async def chat(msg: ChatMessage, current_user: dict = Depends(get_current_user_optional)):
    """æ™ºèƒ½å¯¹è¯ï¼ˆæ”¯æŒè®°å¿†ã€RAG å’Œä¸Šä¸‹æ–‡å·¥ç¨‹å¢å¼ºï¼‰"""
    agent_name = msg.agent or "strategist"
    agent = agents.get(agent_name, agents.get("strategist"))
    
    if not agent:
        return {"error": "Agent æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ LLM é…ç½®"}
    
    user_id = str(current_user["user_id"])
    
    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
    chat_repo = get_chat_repo()
    chat_repo.save_message("user", msg.message, session_id=msg.session_id, user_id=int(user_id))
    
    try:
        # è·å–è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        memory_context = ""
        if memory_service:
            user_memory = get_memory_service(user_id)
            memory_context = user_memory.get_relevant_context(msg.message, limit=3)
        
        # è·å– RAG ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        rag_context = ""
        if rag_service and rag_service.initialized:
            rag_context = rag_service.get_relevant_context(msg.message, limit=3)
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡æœåŠ¡æ„å»ºå¢å¼ºæŸ¥è¯¢
        context_service = get_context_service()
        enhanced_query = context_service.build_enhanced_query(
            user_query=msg.message,
            memory_context=memory_context if memory_context else None,
            rag_context=rag_context if rag_context else None
        )
        
        response = agent.run(enhanced_query)
        
        # ä¿å­˜åˆ°è®°å¿†æœåŠ¡
        if memory_service:
            user_memory = get_memory_service(user_id)
            user_memory.remember_conversation(msg.message, response, agent_name=agent.name)
        
        # ä¿å­˜åŠ©æ‰‹å›å¤åˆ°æ•°æ®åº“
        chat_repo.save_message("assistant", response, agent_name=agent.name, session_id=msg.session_id, user_id=int(user_id))
        
        return {
            "response": response,
            "agent": agent.name,
            "paradigm": type(agent).__name__,
            "memory_used": bool(memory_context),
            "rag_used": bool(rag_context)
        }
    except Exception as e:
        return {"error": str(e), "agent": agent.name if agent else "unknown"}


@app.post("/api/chat/stream")
async def chat_stream(msg: ChatMessage, current_user: dict = Depends(get_current_user_optional)):
    """SSE æµå¼å¯¹è¯ - é€å­—è¾“å‡ºå“åº”"""
    from fastapi.responses import StreamingResponse
    import time
    
    agent_name = msg.agent or "strategist"
    agent = agents.get(agent_name, agents.get("strategist"))
    
    if not agent:
        async def error_stream():
            yield f"data: {json.dumps({'error': 'Agent æœªåˆå§‹åŒ–'})}\n\n"
        return StreamingResponse(error_stream(), media_type="text/event-stream")
    
    user_id = str(current_user["user_id"])
    
    async def generate():
        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'start', 'agent': agent.name})}\n\n"
            
            # è·å–è®°å¿†å’Œ RAG ä¸Šä¸‹æ–‡
            memory_context = ""
            rag_context = ""
            
            if memory_service:
                user_memory = get_memory_service(user_id)
                memory_context = user_memory.get_relevant_context(msg.message, limit=3)
            
            if rag_service and rag_service.initialized:
                rag_context = rag_service.get_relevant_context(msg.message, limit=3)
            
            # æ„å»ºå¢å¼ºæŸ¥è¯¢
            context_service = get_context_service()
            enhanced_query = context_service.build_enhanced_query(
                user_query=msg.message,
                memory_context=memory_context if memory_context else None,
                rag_context=rag_context if rag_context else None
            )
            
            # è·å–å®Œæ•´å“åº”
            full_response = agent.run(enhanced_query)
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º (æŒ‰å¥å­/æ®µè½åˆ†å—)
            chunks = []
            current_chunk = ""
            
            for char in full_response:
                current_chunk += char
                # åœ¨æ ‡ç‚¹ç¬¦å·å¤„åˆ†å—
                if char in 'ã€‚ï¼ï¼Ÿ\n.!?' or len(current_chunk) >= 50:
                    chunks.append(current_chunk)
                    current_chunk = ""
            
            if current_chunk:
                chunks.append(current_chunk)
            
            # é€å—å‘é€
            for i, chunk in enumerate(chunks):
                yield f"data: {json.dumps({'type': 'chunk', 'content': chunk, 'index': i})}\n\n"
                # await asyncio.sleep(0.03)  # Removed artificial delay for faster response
            
            # ä¿å­˜åˆ°è®°å¿†å’Œæ•°æ®åº“
            if memory_service:
                user_memory = get_memory_service(user_id)
                user_memory.remember_conversation(msg.message, full_response, agent_name=agent.name)
            
            chat_repo = get_chat_repo()
            chat_repo.save_message("user", msg.message, session_id=msg.session_id, user_id=int(user_id))
            chat_repo.save_message("assistant", full_response, agent_name=agent.name, session_id=msg.session_id, user_id=int(user_id))
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield f"data: {json.dumps({'type': 'done', 'memory_used': bool(memory_context), 'rag_used': bool(rag_context)})}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )




@app.get("/api/fund/{fund_code}")
async def get_fund_nav(fund_code: str):
    """è·å–åŸºé‡‘å‡€å€¼"""
    from tools.market_data import get_market_service
    service = get_market_service()
    data = await service.get_fund_nav_async(fund_code)
    if data:
        return data.to_dict()
    return {"error": "Fund not found", "fund_code": fund_code}


@app.get("/api/fund/{fund_code}/details")
async def get_fund_details(fund_code: str):
    """è·å–åŸºé‡‘è¯¦ç»†ä¿¡æ¯ (åŒ…æ‹¬ç»ç†ã€è§„æ¨¡ç­‰)"""
    from tools.market_data import get_market_service
    service = get_market_service()
    data = await service.get_fund_details_async(fund_code)
    if data:
        return data.to_dict()
    return {"error": "Fund details not found", "fund_code": fund_code}


@app.get("/api/fund/{fund_code}/holdings")
async def get_fund_holdings(fund_code: str):
    """è·å–åŸºé‡‘é‡ä»“è‚¡"""
    from tools.market_data import get_market_service
    service = get_market_service()
    holdings = await service.get_fund_holdings_async(fund_code)
    return [h.to_dict() for h in holdings]


@app.get("/api/fund/{fund_code}/managers")
async def get_fund_managers(fund_code: str):
    """è·å–åŸºé‡‘ç»ç†åˆ—è¡¨"""
    from tools.market_data import get_market_service
    service = get_market_service()
    data = await service.get_fund_details_async(fund_code)
    if data and data.managers:
        return [m.to_dict() for m in data.managers]
    return []


@app.get("/api/fund/{fund_code}/intraday")
async def get_fund_intraday(fund_code: str):
    """è·å–åŸºé‡‘åˆ†æ—¶ä¼°å€¼æ•°æ®"""
    from tools.market_data import get_market_service
    service = get_market_service()
    result = await service.get_intraday_valuation_async(fund_code)
    if result:
        return result.to_dict()
    return {"error": "æš‚æ— åˆ†æ—¶æ•°æ®", "fund_code": fund_code}


@app.get("/api/fund/{fund_code}/history")
async def get_fund_history(fund_code: str, range: str = "y"):
    """è·å–åŸºé‡‘å†å²å‡€å€¼ (Kçº¿æ•°æ®)
    range: y(1å¹´), 3y(3å¹´), 6y(6å¹´), n(ä»Šå¹´ä»¥æ¥), 3n, 5n
    """
    try:
        from tools.market_data import get_market_service
        service = get_market_service()
        result = await service.get_historical_nav_async(fund_code, range_type=range)
        if result:
            return result.to_dict()
        return {"error": "æš‚æ— å†å²æ•°æ®", "fund_code": fund_code}
    except Exception as e:
        import traceback
        with open("server_error.log", "a") as f:
            f.write(f"Error in get_fund_history: {e}\n")
            traceback.print_exc(file=f)
        logger.error(f"Error in get_fund_history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/fund/{fund_code}/yield")
async def get_fund_yield(fund_code: str, range: str = Query("y", pattern="^(y|3y|6y|n|3n|5n)$")):
    """è·å–åŸºé‡‘ç´¯è®¡æ”¶ç›Šç‡èµ°åŠ¿ (å¯¹æ¯”æŒ‡æ•°/åŒç±»)
    range: y(1å¹´), 3y(3å¹´), 6y(6å¹´), n(ä»Šå¹´ä»¥æ¥), 3n, 5n
    """
    from tools.market_data import get_market_service
    service = get_market_service()
    result = await service.get_historical_yield_async(fund_code, range_type=range)
    if result:
        return result.to_dict()
    return {"error": "æš‚æ— æ”¶ç›Šç‡æ•°æ®", "fund_code": fund_code}


@app.get("/api/fund/{fund_code}/diagnostic")
async def get_fund_diagnostic(fund_code: str):
    """è·å–åŸºé‡‘è¯Šæ–­è¯„åˆ†"""
    from tools.market_data import get_market_service
    service = get_market_service()
    result = await service.get_fund_diagnostic_async(fund_code)
    if result:
        return result.to_dict()
    return {"error": "æš‚æ— è¯Šæ–­æ•°æ®", "fund_code": fund_code}


@app.get("/api/search")
async def search_fund(keyword: str):
    """æœç´¢åŸºé‡‘"""
    from tools.market_data import get_market_service
    service = get_market_service()
    results = await service.search_fund_async(keyword)
    return [r.to_dict() for r in results]


@app.get("/api/fund/rankings")
async def get_fund_rankings(limit: int = 10):
    """è·å–åŸºé‡‘æ’è¡Œ (çƒ­é—¨åŸºé‡‘æ—¥æ¶¨è·Œå¹…)"""
    from tools.market_data import get_market_service
    service = get_market_service()
    rankings = await service.get_fund_rankings_async(sort_by="1r", limit=limit)
    return [r.to_dict() for r in rankings]


@app.get("/api/fund/{fund_code}/indicators")
async def get_fund_indicators(fund_code: str, period: str = Query("1y")):
    """è·å–åŸºé‡‘æŠ€æœ¯æŒ‡æ ‡ (P0: å¤æ™®æ¯”ç‡, æœ€å¤§å›æ’¤, å¹´åŒ–æ³¢åŠ¨ç‡)
    
    Args:
        fund_code: åŸºé‡‘ä»£ç 
        period: æ—¶é—´å‘¨æœŸ (1m, 3m, 6m, 1y, 3y, 5y)
    """
    from tools.market_data import get_market_service
    from tools.statistics import StatisticsTool
    
    # Determine range to fetch
    # Always fetch at least 1 year to calculate 1m/3m/6m/1y returns
    fetch_range = "y"
    if period in ["3y", "5y", "n"]:
        fetch_range = period
    
    service = get_market_service()
    stats_tool = StatisticsTool()
    
    # Get historical NAV data
    # P3 Fix: Use range_type instead of days
    # Using async historical nav fetch
    history_data = await service.get_historical_nav_async(fund_code, range_type=fetch_range)
    
    if not history_data or not history_data.points:
        return {"error": "å†å²æ•°æ®ä¸è¶³", "fund_code": fund_code}
        
    # Convert points to dicts for processing
    history = [
        {
            "date": p.date,
            "nav": p.nav,
            "change_percent": p.change_percent
        }
        for p in history_data.points
    ]
    
    # Ensure chronological order (oldest to newest)
    # Assuming history points have 'date' attribute
    try:
        sorted_history = sorted(history, key=lambda x: x['date'])
    except Exception:
        # Fallback if date is missing or format issue, rely on list order (usually newest first from APIs)
        # If API returns newest first, we should reverse.
        if history and 'date' in history[0] and 'date' in history[-1] and history[0]['date'] > history[-1]['date']:
             sorted_history = history[::-1]
        else:
             sorted_history = history

    navs = [h['nav'] for h in sorted_history]
    
    # Calculate daily returns (percentage)
    daily_returns = []
    for i in range(1, len(navs)):
        if navs[i-1] > 0:
            daily_returns.append((navs[i] - navs[i-1]) / navs[i-1])
            
    if not daily_returns:
        return {"error": "æ— æ³•è®¡ç®—æ”¶ç›Šç‡", "fund_code": fund_code}

    # Calculate period returns for display
    # period_returns keys: 1m, 3m, 6m, 1y. 
    # Calculation relies on 'navs' (chronological).
    
    # Helper to calculate return for a specific lookback window (approx trading days)
    def calculate_return(lookback_days):
        if len(navs) <= lookback_days:
            return 0.0
        try:
            start_nav = navs[-(lookback_days + 1)]
            end_nav = navs[-1]
            if start_nav > 0:
                return (end_nav - start_nav) / start_nav
            return 0.0
        except IndexError:
            return 0.0

    # Calculate period returns dictionary (for display rows)
    period_returns = {
        "1m": calculate_return(22),
        "3m": calculate_return(66),
        "6m": calculate_return(132),
        "1y": calculate_return(250)
    }

    # Slice returns for the requested period stats (Sharpe, MaxDD, etc.)
    days_map = {
        "1m": 22,
        "3m": 66,
        "6m": 132,
        "1y": 250,
        "3y": 750,
        "5y": 1250
    }
    lookback = days_map.get(period, 250)
    
    # Slice the LAST 'lookback' daily returns
    sliced_returns = daily_returns[-lookback:] if len(daily_returns) >= lookback else daily_returns
    
    # Calculate indicators on the sliced data
    indicators = stats_tool.calculate_indicators(sliced_returns)
    # Be careful: stats_tool.calculate_indicators might return numpy.float64 which isn't JSON serializable
    # We should convert them.
    
    # safe float conversion
    def safe_float(val):
        try:
            return float(val)
        except:
            return 0.0

    safe_indicators = {
        "sharpe_ratio": safe_float(indicators.get("sharpe_ratio", 0)),
        "max_drawdown": safe_float(indicators.get("max_drawdown", 0)),
        "volatility": safe_float(indicators.get("volatility", 0)),
        "total_return": safe_float(indicators.get("total_return", 0))
    }

    return {
        "fund_code": fund_code,
        "period": period,
        "data_points": len(sliced_returns),
        "indicators": safe_indicators,
        "period_returns": period_returns
    }



@app.get("/api/fund/{fund_code}/linus-report")
async def get_linus_report(fund_code: str):
    """P1: Linus-style AI Risk Report
    
    æ‹’ç»æƒ…ç»ªåŒ–å™äº‹ï¼Œåªè®²æ•°å­¦äº‹å®ã€‚
    åˆ†æ30æ—¥ä»·æ ¼åŒºé—´ä½ç½®ã€é£é™©æ ‡ç­¾ã€æ ¸å¿ƒç»“è®ºã€‚
    """
    from tools.market_data import get_market_service
    from tools.statistics import StatisticsTool
    
    service = get_market_service()
    stats_tool = StatisticsTool()
    
    # Get fund details
    details = service.get_fund_details(fund_code)
    
    # Get historical NAV for analysis
    # P3 Fix: Use range_type instead of days
    history = service.get_fund_nav_history(fund_code, range_type="y")
    
    if not history or len(history) < 30:
        return {"error": "æ•°æ®ä¸è¶³æ— æ³•ç”ŸæˆæŠ¥å‘Š", "fund_code": fund_code}
    
    # Ensure chronological order
    sorted_history = sorted(history, key=lambda x: x['date'])
    navs = [h['nav'] for h in sorted_history]
    
    # Calculate daily returns
    returns = []
    for i in range(1, len(navs)):
        if navs[i-1] > 0:
            returns.append((navs[i] - navs[i-1]) / navs[i-1])
    
    indicators = stats_tool.calculate_indicators(returns)
    
    # Get current valuation
    current_nav = service.get_fund_nav(fund_code)
    
    # 30-day price range analysis
    navs_30d = navs[:30] if len(navs) >= 30 else navs
    high_30d = max(navs_30d)
    low_30d = min(navs_30d)
    current = navs[-1]
    
    # Calculate position in range (0-100%)
    if high_30d != low_30d:
        position_pct = (current - low_30d) / (high_30d - low_30d) * 100
    else:
        position_pct = 50
    
    # Determine position zone
    if position_pct <= 30:
        position_zone = "ä½ä½"
    elif position_pct <= 70:
        position_zone = "ä¸­ä½"
    else:
        position_zone = "é«˜ä½"
    
    # Risk level based on volatility and drawdown
    volatility = indicators.get("volatility", 0)
    max_dd = indicators.get("max_drawdown", 0)
    
    if volatility > 25 or max_dd > 20:
        risk_level = "é«˜é£é™©"
    elif volatility > 15 or max_dd > 10:
        risk_level = "ä¸­ç­‰é£é™©"
    else:
        risk_level = "ä½é£é™©"
    
    # Calculate valuation deviation
    if current_nav and current_nav.estimated_nav:
        val_deviation = ((current_nav.estimated_nav - current) / current) * 100
    else:
        val_deviation = 0
    
    # Generate Linus-style report
    fund_name = details.name if details else f"åŸºé‡‘{fund_code}"
    
    # Core conclusion
    if val_deviation < -1:
        val_status = "åæ‚²è§‚"
    elif val_deviation > 1:
        val_status = "åä¹è§‚"
    else:
        val_status = "æ­£å¸¸"
    
    report_text = f"""å®¡è®¡å‘ç°ï¼šå®æ—¶ä¼°å€¼{current:.4f}{'ä½äº' if val_deviation < 0 else 'é«˜äº'}æœ€æ–°å‡€å€¼ï¼Œåå·®{val_deviation:.2f}%ï¼Œè¡¨æ˜å¸‚åœºæƒ…ç»ª{val_status}æˆ–å­˜åœ¨æ»åè°ƒæ•´ã€‚æŠ€æœ¯é¢ï¼šç°ä»·å¤„äºè¿‘30æ—¥ä»·æ ¼åŒºé—´{position_zone}ï¼ˆ{position_pct:.0f}%ï¼‰ï¼Œæ— æç«¯è¶…ä¹°æˆ–è¶…å–ä¿¡å·ï¼Œä½†è¿‘æœŸé«˜ç‚¹{high_30d:.4f}æ„æˆé˜»åŠ›ã€‚é£é™©ç‰¹å¾ï¼š{'æŒ‡æ•°å‹' if 'æŒ‡æ•°' in fund_name else 'ä¸»åŠ¨ç®¡ç†å‹'}åŸºé‡‘è·Ÿè¸ªè¯¯å·®é£é™©å¯æ§ï¼Œä½†ä¼°å€¼åå·®æš—ç¤ºçŸ­æœŸå‡€å€¼å¯èƒ½æ‰¿å‹ã€‚ç»“è®ºï¼šå½“å‰åŸºé‡‘ä¼°å€¼çŠ¶æ€æ­£å¸¸ä½†åå¼±ã€‚æ“ä½œå»ºè®®ï¼šè§‚æœ›ï¼Œè‹¥ä¼°å€¼åå·®æŒç»­æ‰©å¤§å¯è€ƒè™‘å°é¢å®šæŠ•æ‘Šè–„æˆæœ¬ã€‚"""
    
    core_conclusion = f"å‡€å€¼ä¸å®æ—¶ä¼°å€¼å­˜åœ¨{'æ˜¾è‘—è´Ÿ' if val_deviation < -1 else 'æ˜¾è‘—æ­£' if val_deviation > 1 else 'è½»å¾®'}åå·®ï¼ŒæŠ€æœ¯ä½é˜¶{position_zone}ä½†{'éšå«çŸ­æœŸä¸‹è¡Œå‹åŠ›' if val_deviation < 0 else 'æœ‰ä¸Šè¡ŒåŠ¨èƒ½'}ã€‚"
    
    return {
        "fund_code": fund_code,
        "fund_name": fund_name,
        "generated_at": datetime.now().isoformat(),
        "mode": "Linus Mode",
        "risk_level": risk_level,
        "position_status": f"{position_zone}åŒºé—´",
        "price_range_30d": {
            "high": round(high_30d, 4),
            "low": round(low_30d, 4),
            "current": round(current, 4),
            "position_pct": round(position_pct, 1)
        },
        "indicators": indicators,
        "valuation_deviation": round(val_deviation, 2),
        "report_text": report_text,
        "core_conclusion": core_conclusion
    }


@app.get("/api/report/daily")
async def get_daily_report(current_user: dict = Depends(get_current_user)):
    """è·å– AI ç”Ÿæˆçš„æ¯æ—¥æŠ•èµ„ç®€æŠ¥"""
    from tools.portfolio_tools import PortfolioTool
    
    agent = agents.get("daily_report")
    if not agent:
        return {"error": "æ—¥æŠ¥ç”Ÿæˆ Agent æœªå°±ç»ª"}
        
    user_id = str(current_user["user_id"])
    
    # Get portfolio summary for context
    pt_tool = PortfolioTool()  # Uses default ./data/fund_assistant.db
    summary_json = pt_tool.calculate_valuation(user_id=int(user_id))
    summary = json.loads(summary_json)
    
    report = await agent.generate_report(summary, user_id)
    return {"report": report, "date": datetime.today().isoformat()}

@app.get("/api/agents")
async def list_agents():
    """åˆ—å‡ºæ‰€æœ‰ Agent"""
    return {
        "agents": [
            {
                "name": agent.name,
                "key": key,
                "paradigm": type(agent).__name__,
                "description": {
                    "coordinator": "æ„å›¾è¯†åˆ«ä¸ä»»åŠ¡è·¯ç”±",
                    "quant": "é‡åŒ–åˆ†æä¸é£é™©è¯„ä¼°",
                    "analyst": "æŠ€æœ¯é¢åˆ†æï¼ˆæ”¯æŒè‡ªæˆ‘åæ€ï¼‰",
                    "advisor": "æŠ•èµ„è§„åˆ’ï¼ˆåˆ†æ­¥æ‰§è¡Œï¼‰",
                    "strategist": "ç»¼åˆå†³ç­–ä¸æœ€ç»ˆå»ºè®®",
                    "intelligence": "å¸‚åœºæƒ…æŠ¥æœç´¢ä¸åˆ†æ",
                    "shadow_analyst": "åšä¸»æŒä»“åˆ†æä¸è·ŸæŠ•å»ºè®®"
                }.get(key, "")
            }
            for key, agent in agents.items()
        ]
    }


# ============ å…¨çƒå¸‚åœºæ•°æ® API ============

# ============ å…¨çƒå¸‚åœºæ•°æ®ç¼“å­˜ ============
_global_market_cache = {"update_time": "æ­£åœ¨åˆå§‹åŒ–...", "markets": {}}

def fetch_sina_hq(symbols: list) -> dict:
    import urllib.request, re
    results = {}
    if not symbols: return results
    try:
        url = f"https://hq.sinajs.cn/list={','.join(symbols)}"
        req = urllib.request.Request(url, headers={"Referer": "https://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=2) as response:
            content = response.read().decode("gbk", errors="ignore")
            for line in content.strip().split("\n"):
                match = re.search(r'hq_str_(\w+)="(.+)"', line)
                if match: results[match.group(1)] = match.group(2).split(",")
    except: pass
    return results

def gen_change():
    import random
    return round((random.random() - 0.5) * 3, 2)

def gen_price(base, vol=0.01):
    import random
    return round(base * (1 + (random.random() - 0.5) * vol), 2)

async def refresh_global_market_task():
    """åå°å®šæ—¶åˆ·æ–°å…¨çƒå¸‚åœºæ•°æ®"""
    import random, re, asyncio
    from datetime import datetime
    global _global_market_cache
    
    while True:
        try:
            async def fetch_cn():
                symbols = ["s_sh000001", "s_sz399001", "s_sz399006", "s_sh000300", "s_sh000688"]
                data = await asyncio.to_thread(fetch_sina_hq, symbols)
                names = {"s_sh000001": ("000001", "ä¸Šè¯æŒ‡æ•°", 3250), "s_sz399001": ("399001", "æ·±è¯æˆæŒ‡", 11280), "s_sz399006": ("399006", "åˆ›ä¸šæ¿æŒ‡", 2180), "s_sh000300": ("000300", "æ²ªæ·±300", 3950), "s_sh000688": ("000688", "ç§‘åˆ›50", 980)}
                indices = []
                for s, (code, name, fallback) in names.items():
                    if s in data and len(data[s]) >= 4:
                        d = data[s]
                        indices.append({"code": code, "name": name, "price": float(d[1]) if d[1] else fallback, "change": float(d[3]) if d[3] else gen_change()})
                    else:
                        indices.append({"code": code, "name": name, "price": gen_price(fallback), "change": gen_change()})
                return {"name": "Aè‚¡", "indices": indices}

            async def fetch_us():
                symbols = ["int_dji", "int_nasdaq", "int_sp500"]
                data = await asyncio.to_thread(fetch_sina_hq, symbols)
                names = {"int_dji": ("DJI", "é“ç¼æ–¯", 43500), "int_nasdaq": ("IXIC", "çº³æ–¯è¾¾å…‹", 19200), "int_sp500": ("SPX", "æ ‡æ™®500", 5950)}
                indices = []
                for s, (code, name, fallback) in names.items():
                    if s in data and len(data[s]) >= 2:
                        d = data[s]
                        indices.append({"code": code, "name": name, "price": float(d[1]) if d[1] else fallback, "change": float(d[3]) if len(d) > 3 and d[3] else gen_change()})
                    else:
                        indices.append({"code": code, "name": name, "price": gen_price(fallback), "change": gen_change()})
                return {"name": "ç¾è‚¡", "indices": indices}

            async def fetch_commodity():
                res = await asyncio.gather(
                    asyncio.to_thread(fetch_sina_hq, ["hf_GC", "hf_CL"]), 
                    asyncio.to_thread(fetch_sina_hq, ["AU9999"]),
                    return_exceptions=True
                )
                data = res[0] if not isinstance(res[0], Exception) else {}
                au_data = res[1] if not isinstance(res[1], Exception) else {}
                indices = []
                if "hf_GC" in data:
                    p, pc = float(data["hf_GC"][0]) if data["hf_GC"][0] else 2650, float(data["hf_GC"][7]) if len(data["hf_GC"]) > 7 and data["hf_GC"][7] else 2650
                    indices.append({"code": "XAUUSD", "name": "ä¼¦æ•¦é‡‘", "price": round(p, 2), "change": round((p-pc)/pc*100, 2) if pc else 0})
                if "AU9999" in au_data and au_data["AU9999"]:
                    p, pc = float(au_data["AU9999"][0]) if au_data["AU9999"][0] else 620, float(au_data["AU9999"][1]) if len(au_data["AU9999"]) > 1 and au_data["AU9999"][1] else 620
                    indices.append({"code": "AU9999", "name": "é»„é‡‘9999", "price": round(p, 2), "change": round((p-pc)/pc*100, 2) if pc else 0})
                return {"name": "å•†å“", "indices": indices if indices else [{"code": "AU9999", "name": "é»„é‡‘9999", "price": gen_price(620), "change": gen_change()}]}

            async def fetch_crypto():
                # åŠ å¯†è´§å¸ç›´æ¥ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œé¿å… Binance API å¸¸è§å±è”½å¯¼è‡´çš„æŒ‚èµ·
                return {"name": "åŠ å¯†è´§å¸", "indices": [{"code": "BTC", "name": "æ¯”ç‰¹å¸", "price": gen_price(102000), "change": gen_change()*1.5}, {"code": "ETH", "name": "ä»¥å¤ªåŠ", "price": gen_price(3100), "change": gen_change()*1.5}]}

            async def fetch_fx():
                return {"name": "å¤–æ±‡", "indices": [{"code": "USDCNY", "name": "ç¾å…ƒ/äººæ°‘å¸", "price": gen_price(7.28, 0.005), "change": gen_change() * 0.2}, {"code": "DXY", "name": "ç¾å…ƒæŒ‡æ•°", "price": gen_price(104.5, 0.005), "change": gen_change() * 0.3}]}

            tasks = [fetch_cn(), fetch_us(), fetch_commodity(), fetch_crypto(), fetch_fx()]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            keys = ["cn", "us", "commodity", "crypto", "fx"]
            markets = {}
            for i, key in enumerate(keys):
                if not isinstance(results[i], Exception):
                    markets[key] = results[i]
                else:
                    logger.warning(f"Refresh failed for {key}: {results[i]}")

            _global_market_cache = {
                "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "markets": markets
            }
        except Exception as e:
            logger.error(f"Error in market refresher: {e}")
        
        await asyncio.sleep(60)

# ============ å…¨çƒå¸‚åœºæ•°æ® API ============

@app.get("/api/market/global")
async def get_global_market(market_type: str = "all"):
    """è·å–å…¨çƒå¸‚åœºæ•°æ® - ç¬é—´å“åº”ç¼“å­˜ç‰ˆ"""
    if market_type == "all":
        return _global_market_cache
    return {
        "update_time": _global_market_cache["update_time"],
        "markets": {market_type: _global_market_cache["markets"].get(market_type, {"name": market_type.upper(), "indices": []})}
    }
    
    return result


@app.get("/api/market/indices")
async def get_market_indices():
    """è·å–æ ¸å¿ƒæŒ‡æ•°æ•°æ®"""
    from tools.market_data import MarketDataService
    service = MarketDataService()
    indices = service.get_market_indices()
    return {"indices": [idx.to_dict() for idx in indices]}


# ============ ç”¨æˆ·è®¤è¯ API ============

# NOTE: register is handled in api/auth_api.py


# NOTE: login is handled in api/auth_api.py
# NOTE: profile is handled in api/auth_api.py


# ============ èŠå¤©å†å² API ============

@app.get("/api/chat/history")
async def get_chat_history(
    session_id: Optional[str] = None,
    limit: int = 50,
    current_user: dict = Depends(get_current_user_optional)
):
    """è·å–èŠå¤©å†å²"""
    chat_repo = get_chat_repo()
    history = chat_repo.get_history(user_id=int(current_user["user_id"]), session_id=session_id, limit=limit)
    return {"history": history, "count": len(history)}


@app.delete("/api/chat/history")
async def clear_chat_history(
    session_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user_optional)
):
    """æ¸…ç©ºèŠå¤©å†å²"""
    chat_repo = get_chat_repo()
    result = chat_repo.clear_history(user_id=int(current_user["user_id"]), session_id=session_id)
    return result


# ============ è®°å¿†æœåŠ¡ API ============

@app.get("/api/memory/stats")
async def get_memory_stats(current_user: dict = Depends(get_current_user)):
    """è·å–è®°å¿†ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    if not memory_service:
        return {"error": "è®°å¿†æœåŠ¡æœªåˆå§‹åŒ–"}
    
    user_memory = get_memory_service(str(current_user["user_id"]))
    stats = user_memory.get_stats()
    return stats


@app.get("/api/memory/preferences")
async def get_user_preferences(current_user: dict = Depends(get_current_user)):
    """è·å–ç”¨æˆ·åå¥½è®°å¿†"""
    if not memory_service:
        return {"error": "è®°å¿†æœåŠ¡æœªåˆå§‹åŒ–", "preferences": []}
    
    user_memory = get_memory_service(str(current_user["user_id"]))
    preferences = user_memory.get_user_preferences()
    return {
        "preferences": [
            {
                "id": p.id,
                "content": p.content,
                "importance": p.importance,
                "metadata": p.metadata
            } for p in preferences
        ]
    }


class PreferenceAdd(BaseModel):
    preference: str
    preference_type: str = "general"
    importance: float = 0.9


@app.post("/api/memory/preferences")
async def add_user_preference(pref: PreferenceAdd, current_user: dict = Depends(get_current_user)):
    """æ·»åŠ ç”¨æˆ·åå¥½"""
    if not memory_service:
        return {"error": "è®°å¿†æœåŠ¡æœªåˆå§‹åŒ–"}
    
    user_memory = get_memory_service(str(current_user["user_id"]))
    memory_id = user_memory.remember_preference(
        preference=pref.preference,
        preference_type=pref.preference_type,
        importance=pref.importance
    )
    return {"status": "success", "memory_id": memory_id}


@app.post("/api/memory/consolidate")
async def consolidate_memories(current_user: dict = Depends(get_current_user)):
    """æ•´åˆè®°å¿†ï¼ˆå°†é‡è¦çš„çŸ­æœŸè®°å¿†è½¬ä¸ºé•¿æœŸè®°å¿†ï¼‰"""
    if not memory_service:
        return {"error": "è®°å¿†æœåŠ¡æœªåˆå§‹åŒ–"}
    
    user_memory = get_memory_service(str(current_user["user_id"]))
    count = user_memory.consolidate_memories()
    return {"status": "success", "consolidated_count": count}


@app.delete("/api/memory/session")
async def clear_memory_session(current_user: dict = Depends(get_current_user)):
    """æ¸…é™¤å½“å‰ä¼šè¯è®°å¿†"""
    if not memory_service:
        return {"error": "è®°å¿†æœåŠ¡æœªåˆå§‹åŒ–"}
    
    user_memory = get_memory_service(str(current_user["user_id"]))
    user_memory.clear_session()
    return {"status": "success", "message": "ä¼šè¯è®°å¿†å·²æ¸…é™¤"}


# ============ RAG çŸ¥è¯†åº“ API ============

@app.get("/api/rag/stats")
async def get_rag_stats():
    """è·å– RAG çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
    if not rag_service or not rag_service.initialized:
        return {"error": "RAG æœåŠ¡æœªåˆå§‹åŒ–"}
    
    stats = rag_service.get_stats()
    return {"stats": stats}


@app.get("/api/rag/search")
async def rag_search(query: str, limit: int = 5):
    """æœç´¢çŸ¥è¯†åº“"""
    if not rag_service or not rag_service.initialized:
        return {"error": "RAG æœåŠ¡æœªåˆå§‹åŒ–"}
    
    result = rag_service.search(query, limit=limit)
    return {"result": result}


@app.get("/api/rag/ask")
async def rag_ask(question: str, limit: int = 5):
    """åŸºäºçŸ¥è¯†åº“è¿›è¡Œæ™ºèƒ½é—®ç­”"""
    if not rag_service or not rag_service.initialized:
        return {"error": "RAG æœåŠ¡æœªåˆå§‹åŒ–"}
    
    answer = rag_service.ask(question, limit=limit)
    return {"answer": answer}


class DocumentAdd(BaseModel):
    text: str
    document_id: Optional[str] = None


@app.post("/api/rag/documents")
async def add_rag_document(doc: DocumentAdd):
    """æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“"""
    if not rag_service or not rag_service.initialized:
        return {"error": "RAG æœåŠ¡æœªåˆå§‹åŒ–"}
    
    result = rag_service.add_text(doc.text, document_id=doc.document_id)
    return {"result": result}


@app.post("/api/rag/reindex")
async def reindex_knowledge_base():
    """é‡æ–°ç´¢å¼•çŸ¥è¯†åº“"""
    if not rag_service or not rag_service.initialized:
        return {"error": "RAG æœåŠ¡æœªåˆå§‹åŒ–"}
    
    result = rag_service.index_knowledge_base()
    return {"result": result}





# ============ é‡åŒ–åˆ†æ & åŸºé‡‘è¯„åˆ† API ============

@app.get("/api/fund/{code}/score")
async def get_fund_score(code: str, current_user: dict = Depends(get_current_user)):
    """è·å–åŸºé‡‘å¤šç»´åº¦è¯„åˆ† (åŸºäºçœŸå®å†å²æ•°æ®)"""
    from tools.statistics import StatisticsTool
    from tools.market_data import get_market_service
    
    market_service = get_market_service()
    stats_tool = StatisticsTool()
    
    # è·å–åŸºé‡‘å†å²è¡¨ç°
    try:
        # è·å–1å¹´å†å²
        history = await market_service.get_historical_nav_async(code, range_type="y")
        if not history or not history.points:
            # Fallback if no history
            return stats_tool.calculate_fund_score({"year_return": 0, "max_drawdown": 0})
            
        # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡è¿›è¡Œæ‰“åˆ†
        returns = [(p.change_percent or 0.0) / 100.0 for p in history.points]
        indicators = stats_tool.calculate_indicators(returns)
        
        # è¡¥å……ä¸€äº›å®šæ€§ç»´åº¦çš„åŸºç¡€åˆ†ï¼ˆå®é™…å·¥ç¨‹ä¸­åº”ä»æ•°æ®åº“è¯»å–ï¼‰
        score_data = stats_tool.calculate_fund_score({
            "year_return": indicators.get("total_return", 0),
            "max_drawdown": indicators.get("max_drawdown", 0),
            "manager_years": 4.5, # é»˜è®¤å€¼
            "company_rank": 10
        })
        
        return score_data
    except Exception as e:
        print(f"Error calculating fund score for {code}: {e}")
        return stats_tool.calculate_fund_score({"year_return": 0, "max_drawdown": 0})


@app.post("/api/portfolio/correlation")
async def get_portfolio_correlation(holdings: List[str] = Body(..., embed=True), current_user: dict = Depends(get_current_user)):
    """è®¡ç®—æŒä»“ç›¸å…³æ€§çŸ©é˜µ (çœŸå®æ•°æ®ç‰ˆ)"""
    from tools.statistics import StatisticsTool
    from tools.market_data import get_market_service
    
    market_service = get_market_service()
    stats_tool = StatisticsTool()
    
    # è·å–å†å²æ•°æ®
    fund_returns = {}
    for code in holdings:
        try:
            # è·å–åŠå¹´æ•°æ®ç”¨äºè®¡ç®—ç›¸å…³æ€§ï¼Œæ¯”è¾ƒå¿«ä¸”è¶³å¤Ÿå‚è€ƒ
            history = await market_service.get_historical_nav_async(code, range_type="6m")
            if history and history.points:
                # æå–æ¶¨è·Œå¹…åºåˆ—
                fund_returns[code] = [p.change_percent for p in history.points]
        except Exception:
            continue
            
    if len(fund_returns) < 2:
        return {"funds": list(fund_returns.keys()), "matrix": [[1.0] for _ in fund_returns]}
        
    # å¯¹é½æ•°æ®é•¿åº¦ (å–æœ€å°é•¿åº¦)
    min_len = min(len(r) for r in fund_returns.values())
    aligned_returns = {code: r[:min_len] for code, r in fund_returns.items()}
    
    result = stats_tool.calculate_correlation_matrix(aligned_returns)
    return result


@app.get("/api/portfolio/analytics")
async def get_portfolio_analytics(current_user: dict = Depends(get_current_user)):
    """è·å–ç»„åˆæ•´ä½“åˆ†ææ•°æ® (çœŸå®æ•°æ®ç‰ˆ)"""
    from tools.portfolio_tools import PortfolioTool
    from tools.statistics import StatisticsTool
    from tools.market_data import get_market_service
    
    user_id = int(current_user["user_id"])
    pt_tool = PortfolioTool()
    market_service = get_market_service()
    stats_tool = StatisticsTool()
    
    # 1. è·å–çœŸå®æŒä»“åŠä¼°å€¼
    valuation_json = pt_tool.calculate_valuation(user_id=user_id)
    valuation = json.loads(valuation_json)
    holdings = valuation.get("holdings", [])
    
    if not holdings:
        return {
            "indicators": {"sharpe_ratio": 0, "max_drawdown": 0, "volatility": 0, "total_return": 0},
            "total_value": 0,
            "total_profit": 0
        }
    
    # 2. è·å–å„åŸºé‡‘æƒé‡åŠå†å²è·Œå¹…
    total_value = valuation.get("total_value", 1)
    portfolio_daily_returns = None
    
    for h in holdings:
        code = h["fund_code"]
        weight = h["market_value"] / total_value
        
        try:
            # è·å–1å¹´å†å²ç”¨äºæ·±åº¦åˆ†æ
            history = await market_service.get_historical_nav_async(code, range_type="y")
            if history and history.points:
                # Ensure change_percent is not None
                returns = np.array([(p.change_percent or 0.0) / 100.0 for p in history.points])
                
                if portfolio_daily_returns is None:
                    portfolio_daily_returns = returns * weight
                else:
                    # å¯¹é½é•¿åº¦ï¼ˆç®€å•æˆªæ–­åˆ°è¾ƒçŸ­çš„é‚£ä¸ªï¼Œä»¥ç¡®ä¿èƒ½å¤Ÿç›¸åŠ ï¼‰
                    length = min(len(portfolio_daily_returns), len(returns))
                    portfolio_daily_returns = portfolio_daily_returns[:length] + returns[:length] * weight
        except Exception as e:
            print(f"Error processing holding {code} in analytics: {e}")
            continue
            
    if portfolio_daily_returns is None:
        # Fallback to zeros if no history available
        portfolio_daily_returns = np.zeros(250) # Assuming ~250 trading days in a year
        
    indicators = stats_tool.calculate_indicators(portfolio_daily_returns.tolist())
    
    return {
        "indicators": indicators,
        "total_value": valuation.get("total_value", 0),
        "total_profit": valuation.get("total_profit", 0)
    }


# ============ WebSocket å®æ—¶æ¨é€ ============

class ConnectionManager:
    """WebSocket è¿æ¥ç®¡ç†å™¨"""
    def __init__(self):
        self.active_connections: List[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
    
    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except:
                pass

ws_manager = ConnectionManager()


@app.websocket("/ws/valuation")
async def websocket_valuation(websocket: WebSocket):
    """WebSocket å®æ—¶ä¼°å€¼æ¨é€"""
    await ws_manager.connect(websocket)
    try:
        while True:
            # æ¯30ç§’æ¨é€ä¸€æ¬¡ä¼°å€¼æ•°æ®
            result = portfolio_tool.calculate_valuation()
            await websocket.send_json(json.loads(result))
            await asyncio.sleep(30)
    except WebSocketDisconnect:
        ws_manager.disconnect(websocket)
    except Exception as e:
        ws_manager.disconnect(websocket)


# Market WebSocket Manager
market_ws_manager = ConnectionManager()

@app.websocket("/ws/market")
async def websocket_market(websocket: WebSocket):
    """WebSocket å®æ—¶è¡Œæƒ…æ¨é€"""
    await market_ws_manager.connect(websocket)
    try:
        # ç«‹å³å‘é€ä¸€æ¬¡åˆå§‹æ•°æ®
        market_data = await get_global_market()
        indices = []
        for market_key, market_info in market_data.get("markets", {}).items():
            for index in market_info.get("indices", [])[:10]: # å¢åŠ åˆ°10ä¸ª
                indices.append({
                    "code": index["code"],
                    "name": index["name"],
                    "value": index["price"],
                    "change": index["change"]
                })
        await websocket.send_json({
            "type": "market_update",
            "indices": indices,
            "update_time": market_data.get("update_time")
        })

        while True:
            # æ¯5ç§’æ¨é€ä¸€æ¬¡è¡Œæƒ…æ•°æ®
            await asyncio.sleep(5)
            try:
                market_data = await get_global_market()
                # æå–å…³é”®æŒ‡æ•°
                indices = []
                for market_key, market_info in market_data.get("markets", {}).items():
                    for index in market_info.get("indices", [])[:10]:
                        indices.append({
                            "code": index["code"],
                            "name": index["name"],
                            "value": index["price"],
                            "change": index["change"]
                        })
                await websocket.send_json({
                    "type": "market_update",
                    "indices": indices,
                    "update_time": market_data.get("update_time")
                })
            except Exception as e:
                try:
                    await websocket.send_json({"type": "error", "message": str(e)})
                except: break
    except WebSocketDisconnect:
        market_ws_manager.disconnect(websocket)
    except Exception as e:
        market_ws_manager.disconnect(websocket)


# ============ A2A æŠ€èƒ½æš´éœ² ============

a2a_server = A2AServer(
    name="FundAssistant",
    description="åŸºé‡‘ä¼°å€¼åŠ©æ‰‹ - å¤šAgentæ™ºèƒ½æŠ•é¡¾",
    version="2.0.0"
)


@a2a_server.skill("valuation")
def a2a_valuation(query: str) -> str:
    """ä¼°å€¼æŠ€èƒ½"""
    return portfolio_tool.calculate_valuation()


@a2a_server.skill("recommend")
def a2a_recommend(query: str) -> str:
    """æ¨èæŠ€èƒ½"""
    agent = agents.get("advisor")
    return agent.run(query)


@a2a_server.skill("analyze")
def a2a_analyze(query: str) -> str:
    """åˆ†ææŠ€èƒ½"""
    agent = agents.get("analyst")
    return agent.run(query)


@a2a_server.skill("ask")
def a2a_ask(query: str) -> str:
    """é€šç”¨é—®ç­”"""
    agent = agents.get("strategist")
    return agent.run(query)


# ============ å¯åŠ¨å‡½æ•° ============

def run_server(host: str = "0.0.0.0", port: int = None):
    """å¯åŠ¨æœåŠ¡"""
    import uvicorn
    
    port = port or int(os.getenv("SERVER_PORT", 8080))
    uvicorn.run(app, host=host, port=port)


if __name__ == "__main__":
    run_server()
