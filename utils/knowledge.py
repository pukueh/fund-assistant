"""RAG çŸ¥è¯†åº“ç®¡ç† - ä½¿ç”¨ HelloAgents RAG Pipeline"""

import os
from typing import List, Dict, Optional

# å°è¯•å¯¼å…¥ HelloAgents RAG æ¨¡å—
try:
    from hello_agents.memory.rag import (
        load_and_chunk_texts,
        index_chunks,
        search_vectors,
        embed_query
    )
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("âš ï¸ RAG æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•å…³é”®è¯æœç´¢")


class FundKnowledgeBase:
    """åŸºé‡‘çŸ¥è¯†åº“ - ä½¿ç”¨ HelloAgents RAG"""
    
    def __init__(self, knowledge_dir: str = "./knowledge"):
        self.knowledge_dir = knowledge_dir
        self.namespace = "fund_knowledge"
        self.indexed = False
        
        # ç®€å•çš„å…³é”®è¯ç´¢å¼•ä½œä¸ºåå¤‡
        self._simple_index = {}
        
    def build_index(self) -> bool:
        """æ„å»ºçŸ¥è¯†åº“ç´¢å¼•"""
        # è·å–çŸ¥è¯†æ–‡ä»¶
        knowledge_files = []
        if os.path.exists(self.knowledge_dir):
            for f in os.listdir(self.knowledge_dir):
                if f.endswith(('.md', '.txt', '.pdf')):
                    knowledge_files.append(os.path.join(self.knowledge_dir, f))
        
        if not knowledge_files:
            print(f"âš ï¸ æœªæ‰¾åˆ°çŸ¥è¯†æ–‡ä»¶: {self.knowledge_dir}")
            return False
        
        print(f"ğŸ“š æ‰¾åˆ° {len(knowledge_files)} ä¸ªçŸ¥è¯†æ–‡ä»¶")
        
        if RAG_AVAILABLE:
            try:
                # ä½¿ç”¨ HelloAgents RAG Pipeline
                chunks = load_and_chunk_texts(
                    paths=knowledge_files,
                    chunk_size=800,
                    chunk_overlap=100,
                    namespace=self.namespace
                )
                print(f"ğŸ“„ åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")
                
                # ç´¢å¼•
                index_chunks(chunks=chunks, rag_namespace=self.namespace)
                print("âœ… RAG ç´¢å¼•æ„å»ºå®Œæˆ")
                self.indexed = True
                return True
            except Exception as e:
                print(f"âš ï¸ RAG ç´¢å¼•å¤±è´¥: {e}")
        
        # åå¤‡: ç®€å•å…³é”®è¯ç´¢å¼•
        self._build_simple_index(knowledge_files)
        self.indexed = True
        return True
    
    def _build_simple_index(self, files: List[str]):
        """æ„å»ºç®€å•çš„å…³é”®è¯ç´¢å¼•"""
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # æŒ‰æ®µè½åˆ‡åˆ†
                paragraphs = content.split('\n\n')
                for i, para in enumerate(paragraphs):
                    if para.strip():
                        # æå–å…³é”®è¯
                        words = set(para.lower().split())
                        self._simple_index[f"{file_path}:{i}"] = {
                            "content": para.strip(),
                            "keywords": words,
                            "source": os.path.basename(file_path)
                        }
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        print(f"âœ… ç®€å•ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…± {len(self._simple_index)} ä¸ªæ®µè½")
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """æœç´¢çŸ¥è¯†åº“"""
        if not self.indexed:
            self.build_index()
        
        if RAG_AVAILABLE:
            try:
                results = search_vectors(
                    query=query,
                    top_k=top_k,
                    rag_namespace=self.namespace
                )
                return [
                    {"content": r.get("text", ""), "score": r.get("score", 0)}
                    for r in results
                ]
            except Exception as e:
                print(f"âš ï¸ RAG æœç´¢å¤±è´¥: {e}")
        
        # åå¤‡: ç®€å•å…³é”®è¯æœç´¢
        return self._simple_search(query, top_k)
    
    def _simple_search(self, query: str, top_k: int) -> List[Dict]:
        """ç®€å•å…³é”®è¯æœç´¢"""
        query_words = set(query.lower().split())
        
        scored_results = []
        for key, item in self._simple_index.items():
            # è®¡ç®—å…³é”®è¯é‡å 
            overlap = len(query_words & item["keywords"])
            if overlap > 0:
                scored_results.append({
                    "content": item["content"],
                    "score": overlap / len(query_words),
                    "source": item["source"]
                })
        
        # æ’åº
        scored_results.sort(key=lambda x: x["score"], reverse=True)
        return scored_results[:top_k]
    
    def get_context(self, query: str, max_chars: int = 2000) -> str:
        """è·å–ä¸æŸ¥è¯¢ç›¸å…³çš„ä¸Šä¸‹æ–‡"""
        results = self.search(query, top_k=5)
        
        context_parts = []
        total_chars = 0
        for r in results:
            content = r["content"]
            if total_chars + len(content) < max_chars:
                context_parts.append(content)
                total_chars += len(content)
            else:
                break
        
        return "\n\n---\n\n".join(context_parts)


# å•ä¾‹
_knowledge_base = None

def get_knowledge_base() -> FundKnowledgeBase:
    """è·å–çŸ¥è¯†åº“å•ä¾‹"""
    global _knowledge_base
    if _knowledge_base is None:
        kb_path = os.path.join(os.path.dirname(__file__), "..", "knowledge")
        _knowledge_base = FundKnowledgeBase(kb_path)
    return _knowledge_base


if __name__ == "__main__":
    # æµ‹è¯•
    kb = get_knowledge_base()
    kb.build_index()
    
    results = kb.search("å®šæŠ•ç­–ç•¥")
    for r in results:
        print(f"Score: {r['score']:.2f}")
        print(f"Content: {r['content'][:100]}...")
        print("-" * 40)
